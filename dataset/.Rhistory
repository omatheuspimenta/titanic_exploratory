class+
children+
old+
nfamily,
family = binomial(link="logit"),
data = train_df)
# predict
predictTrain = predict(lr,type="response")
tapply(predictTrain, train_df$survived, mean) # because need the same length
#         0         1
# 0.2363644 0.6147915
# ROC Curve
# plot 1
ROCRpred <- prediction(predictTrain,train_df$survived)
ROCRperf <- performance(ROCRpred, "tpr","fpr")
plot(ROCRperf,
colorize=TRUE,
print.cutoffs.at=seq(0,1,by=0.1),
text.adj=c(-0.2,1.7),
main="ROC Curve")
# plot 2
roc1=plot.roc(train_df$survived,fitted(lr))
plot(roc1,
print.auc=TRUE,
auc.polygon=TRUE,
grid.col=c("green","red"),
max.auc.polygon=TRUE,
auc.polygon.col="lightgreen",
print.thres=TRUE,
main = "ROC Curve")
# Confusion Matrix with threshold 0.375
test_df$pred <- as.factor(
ifelse(
predict(lr,
newdata = test_df,
type = "response") > 0.328,
1,0)
)
confusionMatrix(test_df$pred, as.factor(test_df$survived))
#  Mcnemar's Test P-Value : 0.00485
#             Sensitivity : 0.7407
#             Specificity : 0.8081
#          Pos Pred Value : 0.8633
#          Neg Pred Value : 0.6557
#              Prevalence : 0.6207
#          Detection Rate : 0.4598
#    Detection Prevalence : 0.5326
#       Balanced Accuracy : 0.7744
#        'Positive' Class : 0
logitor(survived~factor(sex)+
factor(mom)+
class+
children+
old+
nfamily,
data = train_df)
# Odds Ratio:
#              OddsRatio Std. Err.       z     P>|z|
# factor(sex)1 13.074650  2.407140 13.9629 < 2.2e-16 ***
# factor(mom)1  2.074485  0.760266  1.9911   0.04647 *
# class         0.370526  0.038085 -9.6591 < 2.2e-16 ***
# children      9.028415  3.503536  5.6702 1.426e-08 ***
# old           0.541013  0.169742 -1.9580   0.05023 .
# nfamily       0.679631  0.057342 -4.5774 4.707e-06 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
exp(cbind(OR=coef(lr), confint(lr)))
#                      OR     2.5 %     97.5 %
# (Intercept)   3.5049869 2.0741533  5.9864514
# factor(sex)1 13.0746503 9.1702111 18.8846491
# factor(mom)1  2.0744851 1.0270434  4.3355849
# class         0.3705255 0.3019903  0.4520168
# children      9.0284153 4.2911833 19.7140224
# old           0.5410132 0.2892423  0.9913836
# nfamily       0.6796310 0.5718627  0.7959590
remove(lr, roc1, ROCRperf, ROCRpred, test_df, train_df, predictTrain, split)
#####
# Set path
setwd("/home/matheus/Dropbox/06_doutorado/2021_01/Bioestatistica/projeto/dataset/")
#####
# Set path
setwd("/home/matheus/Dropbox/06_doutorado/2021_01/Bioestatistica/projeto/dataset/")
# library("dplyr") #for summary
# library("plyr") #for count
# library("reshape2") #for melted matrix
# library("infotheo") #for information theory
# library("caTools") # for split dataframe
# library("ROCR") # for ROC curve
# library("caret") # for analyze
# library("mfx") # for odds
#####
# Load file
load("titanic3.RData")
#####
# removing some columns
titanic3$name <- NULL
titanic3$ticket <- NULL
titanic3$cabin <- NULL
titanic3$boat <- NULL
titanic3$body <- NULL
titanic3$home.dest <- NULL
titanic3$lastname <- NULL
titanic3$title <- NULL
View(titanic3)
#               ylim = ylim)
# # remove temp variables
# remove(ylim, y, xx, mi, disc_df,t)
# after this, we don't use "sibsp", "parch" and "embarked" columns.
# REMEMBER, this is ONLY A EXAMPLE! If you use this, set a threshold before!!!!!
# the column age will be converted to "categorical dummy"
# Creating dummy variables for "pclass", "sex", "sibsp", "parch", "embarked", "age"
# and, "nfamily"
# using the base R
# pclass class
titanic3$class1 <- ifelse(titanic3$pclass=="1st",1,0)
titanic3$class2 <- ifelse(titanic3$pclass=="2nd",1,0)
titanic3$class3 <- ifelse(titanic3$pclass=="3rd",1,0)
# sex dummy
titanic3$sex <- ifelse(titanic3$sex=="female",1,0)
# sibsp dummy
titanic3$sibsp0 <- ifelse(titanic3$sibsp==0,1,0)
titanic3$sibsp1 <- ifelse(titanic3$sibsp==1,1,0)
titanic3$sibsp2 <- ifelse(titanic3$sibsp==2,1,0)
titanic3$sibsp3 <- ifelse(titanic3$sibsp==3,1,0)
titanic3$sibsp4 <- ifelse(titanic3$sibsp==4,1,0)
titanic3$sibsp5 <- ifelse(titanic3$sibsp==5,1,0)
titanic3$sibsp8 <- ifelse(titanic3$sibsp==8,1,0)
# parch dummy
titanic3$parch0 <- ifelse(titanic3$parch==0,1,0)
titanic3$parch1 <- ifelse(titanic3$parch==1,1,0)
titanic3$parch2 <- ifelse(titanic3$parch==2,1,0)
titanic3$parch3 <- ifelse(titanic3$parch==3,1,0)
titanic3$parch4 <- ifelse(titanic3$parch==4,1,0)
titanic3$parch5 <- ifelse(titanic3$parch==5,1,0)
titanic3$parch6 <- ifelse(titanic3$parch==6,1,0)
titanic3$parch9 <- ifelse(titanic3$parch==9,1,0)
# embarked dummy
titanic3$Cherbourg <- ifelse(titanic3$embarked == "Cherbourg",1,0)
titanic3$Queenstown <- ifelse(titanic3$embarked == "Queenstown",1,0)
titanic3$Southampton <- ifelse(titanic3$embarked == "Southampton",1,0)
# age dummy
titanic3$children <- ifelse(titanic3$age<=11, 1, 0)
titanic3$teenage <- ifelse((titanic3$age>11 & titanic3$age<20), 1, 0)
titanic3$young <- ifelse((titanic3$age>20 & titanic3$age<30), 1, 0)
titanic3$adult <- ifelse((titanic3$age>30 & titanic3$age<60), 1, 0)
titanic3$old <- ifelse(titanic3$age>60, 1, 0)
# # nfamily dummy
titanic3$nfamily1 <- ifelse(titanic3$nfamily == 1,1,0)
titanic3$nfamily2 <- ifelse(titanic3$nfamily == 2,1,0)
titanic3$nfamily3 <- ifelse(titanic3$nfamily == 3,1,0)
titanic3$nfamily4 <- ifelse(titanic3$nfamily == 4,1,0)
titanic3$nfamily5 <- ifelse(titanic3$nfamily == 5,1,0)
titanic3$nfamily6 <- ifelse(titanic3$nfamily == 6,1,0)
titanic3$nfamily7 <- ifelse(titanic3$nfamily == 7,1,0)
titanic3$nfamily8 <- ifelse(titanic3$nfamily == 8,1,0)
titanic3$nfamily11 <- ifelse(titanic3$nfamily == 11,1,0)
#####
# Drop columns
titanic3$pclass <- NULL
titanic3$embarked <- NULL
titanic3$sibsp <- NULL
titanic3$parch <- NULL
titanic3$age <- NULL
View(titanic3)
#####
# Libraries
# library("ggplot2") #for graphics
# library("dplyr") #for summary
# library("plyr") #for count
# library("reshape2") #for melted matrix
# library("infotheo") #for information theory
# library("caTools") # for split dataframe
# library("ROCR") # for ROC curve
library("caret") # for analyze
titanic3[,"fare"]
#####
# Normalize "fare"
preproc1 <- preProcess(titanic3[,"fare"], method=c("scale"))
#####
# Normalize "fare"
preproc1 <- preProcess(titanic3$fare, method=c("scale"))
#####
# Normalize "fare"
preproc1 <- preProcess(titanic3$fare, method=c("range"))
t <- rescale(titanic3$fare)
#####
# Libraries
# library("ggplot2") #for graphics
# library("dplyr") #for summary
# library("plyr") #for count
# library("reshape2") #for melted matrix
# library("infotheo") #for information theory
# library("caTools") # for split dataframe
# library("ROCR") # for ROC curve
library("scales") # for rescale
t <- rescale(titanic3$fare)
t <- rescale(as.numeric(titanic3$fare))
summary(t)
#####
# Normalize "fare"
titanic3$fare <- rescale(as.numeric(titanic3$fare))
remove(t)
View(titanic3)
#####
# Libraries
# library("ggplot2") #for graphics
# library("dplyr") #for summary
# library("plyr") #for count
# library("reshape2") #for melted matrix
# library("infotheo") #for information theory
library("caTools") # for split dataframe
#####
# Classification
# split dataframe
set.seed(7)
split <- sample.split(titanic3$survived, SplitRatio=0.8)
train_df <- subset(titanic3, split == "TRUE")
test_df <- subset(titanic3, split == "FALSE")
library(class)
View(train_df)
train_df[,-1]
train_df[,1]
# KNN - k = 3
knn_3 = knn(train = train_df[,-1],
test = test_df[,-1],
cl = train_df[,1],
prob = TRUE,
k = 3)
knn_3
# KNN - k = 3
knn_3 = knn(train = train_df[,-1],
test = test_df[,-1],
cl = train_df[,1],
k = 3)
# KNN - k = 3
knn_3 = knn(train = train_df[,-1],
test = test_df[,-1],
cl = train_df[,1],
k = 3)
# KNN - k = 3
knn3 = knn(train = train_df[,-1],
test = test_df[,-1],
cl = train_df[,1],
k = 3)
cm_knn3= table(test_df[,1], knn3)
print(matriz_confusao)
print(cm_knn3)
# confusion matrix
confusionMatrix(matriz_confusao)
# confusion matrix
confusionMatrix(cm_knn3)
table(test_df$survived)
library("randomForest") # for RandomForest classifier
train_df[-1]
#                              number = 10,
#                              repeats = 10) # 10 times for each 10fold CrossValidation
# model = train(survived ~.,
#               data = titanic3,
#               trControl = train_control,
#               method = 'knn')
#####
# RandomForest
# with you need improve the method, change the 'ntree'
# suggest: use a grid search to do this
rf100 = randomForest(x = train_df[-1],
y = train_df$survived,
ntree = 100)
train_df$survived
#                              number = 10,
#                              repeats = 10) # 10 times for each 10fold CrossValidation
# model = train(survived ~.,
#               data = titanic3,
#               trControl = train_control,
#               method = 'knn')
#####
# RandomForest
# with you need improve the method, change the 'ntree'
# suggest: use a grid search to do this
rf100 = randomForest(x = train_df[-1],
y = as.factor(train_df$survived),
ntree = 100)
rf100_pred = predict(rf100,
newdata = test_df[-1])
rf100_cm = table(test_df[,1],
rf100_pred)
# confusion matrix
confusionMatrix(rf100_cm)
library(rpart)
# if you need do some crossvalidation, please use the caret library
# train_control = trainControl(method = 'repeatedcv',
#                              number = 10,
#                              repeats = 10) # 10 times for each 10fold CrossValidation
# model = train(survived ~.,
#               data = titanic3,
#               trControl = train_control,
#               method = 'rf')
#####
# Decision Tree
dt = rpart(formula = survived ~ .,
data = titanic3)
dt
print(dt)
library("rpart.plot") # for plot decision tree classifier
install.packages(rpart.plot)
install.packages("rpart.plot")
library("rpart.plot") # for plot decision tree classifier
rpart.plot(dt)
dt_pred = predict(dt,
newdata = test_df[-1],
type = 'class')
# if you need do some crossvalidation, please use the caret library
# train_control = trainControl(method = 'repeatedcv',
#                              number = 10,
#                              repeats = 10) # 10 times for each 10fold CrossValidation
# model = train(survived ~.,
#               data = titanic3,
#               trControl = train_control,
#               method = 'rf')
#####
# Decision Tree
dt = rpart(formula = survived ~ .,
data = titanic3)
dt_pred = predict(dt,
newdata = test_df[-1],
type = 'class')
dt_pred = predict(dt,
newdata = test_df[-1])
dt_cm = table(test_df[,1],
dt_pred)
confusionMatrix(dt_cm)
print(dt_cm)
dt_pred = predict(dt,
newdata = test_df[-1],
type = "class")
# if you need do some crossvalidation, please use the caret library
# train_control = trainControl(method = 'repeatedcv',
#                              number = 10,
#                              repeats = 10) # 10 times for each 10fold CrossValidation
# model = train(survived ~.,
#               data = titanic3,
#               trControl = train_control,
#               method = 'rf')
#####
# Decision Tree
titanic3$survived <- as.factor(titanic3$survived)
dt = rpart(formula = survived ~ .,
data = titanic3)
rpart.plot(dt)
dt_pred = predict(dt,
newdata = test_df[-1],
type = "class")
dt_cm = table(test_df[,1],
dt_pred)
confusionMatrix(dt_cm)
split <- sample.split(titanic3$survived, SplitRatio=0.8)
#####
# KNN - k = 3
# with you need improve the method, change the 'k'
# suggest: use a grid search to do this
knn3 = knn(train = train_df[,-1],
test = test_df[,-1],
cl = train_df[,1],
k = 3)
cm_knn3 = table(test_df[,1], knn3)
# confusion matrix
confusionMatrix(cm_knn3)
#                              number = 10,
#                              repeats = 10) # 10 times for each 10fold CrossValidation
# model = train(survived ~.,
#               data = titanic3,
#               trControl = train_control,
#               method = 'knn')
#####
# RandomForest
# with you need improve the method, change the 'ntree'
# suggest: use a grid search to do this
rf100 = randomForest(x = train_df[-1],
y = train_df$survived,
ntree = 100)
#                              number = 10,
#                              repeats = 10) # 10 times for each 10fold CrossValidation
# model = train(survived ~.,
#               data = titanic3,
#               trControl = train_control,
#               method = 'knn')
#####
# RandomForest
# with you need improve the method, change the 'ntree'
# suggest: use a grid search to do this
rf100 = randomForest(x = train_df[-1],
y = as.factor(train_df$survived),
ntree = 100)
rf100_pred = predict(rf100,
newdata = test_df[-1])
rf100_cm = table(test_df[,1],
rf100_pred)
train_df <- subset(titanic3, split == "TRUE")
test_df <- subset(titanic3, split == "FALSE")
#####
# KNN - k = 3
# with you need improve the method, change the 'k'
# suggest: use a grid search to do this
knn3 = knn(train = train_df[,-1],
test = test_df[,-1],
cl = train_df[,1],
k = 3)
cm_knn3 = table(test_df[,1], knn3)
# confusion matrix
confusionMatrix(cm_knn3)
split <- sample.split(titanic3$survived, SplitRatio=0.8)
train_df <- subset(titanic3, split == "TRUE")
test_df <- subset(titanic3, split == "FALSE")
#####
# KNN - k = 3
# with you need improve the method, change the 'k'
# suggest: use a grid search to do this
knn3 = knn(train = train_df[,-1],
test = test_df[,-1],
cl = train_df[,1],
k = 3)
cm_knn3 = table(test_df[,1], knn3)
# confusion matrix
confusionMatrix(cm_knn3)
#                              number = 10,
#                              repeats = 10) # 10 times for each 10fold CrossValidation
# model = train(survived ~.,
#               data = titanic3,
#               trControl = train_control,
#               method = 'knn')
#####
# RandomForest
# with you need improve the method, change the 'ntree'
# suggest: use a grid search to do this
rf100 = randomForest(x = train_df[-1],
y = train_df$survived,
ntree = 100)
rf100_pred = predict(rf100,
newdata = test_df[-1])
rf100_cm = table(test_df[,1],
rf100_pred)
# confusion matrix
confusionMatrix(rf100_cm)
# if you need do some crossvalidation, please use the caret library
# train_control = trainControl(method = 'repeatedcv',
#                              number = 10,
#                              repeats = 10) # 10 times for each 10fold CrossValidation
# model = train(survived ~.,
#               data = titanic3,
#               trControl = train_control,
#               method = 'rf')
#####
# Decision Tree
dt = rpart(formula = survived ~ .,
data = titanic3)
rpart.plot(dt)
dt_pred = predict(dt,
newdata = test_df[-1],
type = "class")
dt_cm = table(test_df[,1],
dt_pred)
confusionMatrix(dt_cm)
library("h2o") # for neural network
install.packages("h2o")
install.packages("h2o", dependencies = TRUE)
library("h2o") # for neural network
install.packages("h2o")
library("e1071") # for SVM classifier
#          Neg Pred Value : 0.7100
#              Prevalence : 0.6374
#          Detection Rate : 0.5267
#    Detection Prevalence : 0.6183
#       Balanced Accuracy : 0.7869
#        'Positive' Class : 0
#####
# SVM
# with you need improve the method, change the hyperparameters
# suggest: use a grid search to do this
svm.model = svm(formula = survived ~ .,
data = train_df,
type = 'C-classification',
kernel = 'radial',
cost = 10.0)
svm.pred = predict(svm.model,
newdata = test_df[-1])
svm_cm = table(test_df[,1],
svm.pred)
# confusion matrix
confusionMatrix(svm_cm)
#             Specificity : 0.7586
#          Pos Pred Value : 0.8704
#          Neg Pred Value : 0.6600
#              Prevalence : 0.6679
#          Detection Rate : 0.5382
#    Detection Prevalence : 0.6183
#       Balanced Accuracy : 0.7822
#        'Positive' Class : 0
#####
# remove temp variables
remove(cm_knn3, dt_cm, dt_pred, knn_3, rf100_cm, rf100_pred, split, svm_cm,
svm.pred, svm.model, test_df, train_df, dt, rf100)
#             Specificity : 0.7586
#          Pos Pred Value : 0.8704
#          Neg Pred Value : 0.6600
#              Prevalence : 0.6679
#          Detection Rate : 0.5382
#    Detection Prevalence : 0.6183
#       Balanced Accuracy : 0.7822
#        'Positive' Class : 0
#####
# remove temp variables
remove(cm_knn3, knn3, dt_cm, dt_pred, knn_3, rf100_cm, rf100_pred, split, svm_cm,
svm.pred, svm.model, test_df, train_df, dt, rf100)
